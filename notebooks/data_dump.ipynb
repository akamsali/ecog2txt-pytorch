{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from tfrecord_lite import tf_record_iterator\n",
    "from tfrecord.torch.dataset import TFRecordDataset\n",
    "import torch.utils.data as tdata\n",
    "import torch\n",
    "\n",
    "import json"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "block_config_path = '/scratch/gilbreth/akamsali/Research/Makin/ecog2txt-pytorch/conf/block_breakdowns.json'\n",
    "tfrecord_path = '/depot/jgmakin/data/ecog2txt/word_sequence/tf_records'\n",
    "data_path = '/scratch/gilbreth/akamsali/Research/Makin/data/ecog2txt_ak'\n",
    "subjects = ['400', '401', '402', '403']\n",
    "\n",
    "\n",
    "with open(block_config_path) as bf:\n",
    "    block_config_all = json.load(bf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "block_config = block_config_all['400']\n",
    "subject_ID = '400'\n",
    "filtered_files = list(\n",
    "            map(lambda y: (tfrecord_path + \"/EFC\"+ subject_ID + \"_B\" + y[0] + \".tfrecord\", \n",
    "            data_path + \"/EFC\"+ subject_ID + \"_B\" + y[0] + \".json\"), \n",
    "                 block_config.items()))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def convert_to_str(record):\n",
    "    record['text_sequence'] = list(\n",
    "        map(lambda y: y.decode(), record['text_sequence']))\n",
    "    record['text_sequence'].append('<EOS>') \n",
    "    record['phoneme_sequence'] = list(\n",
    "        map(lambda y: y.decode(), record['phoneme_sequence']))\n",
    "    record['ecog_sequence'] = record['ecog_sequence'].tolist() \n",
    "    # print(len(record['phoneme_sequence']))\n",
    "    return record\n",
    "\n",
    "datasets = []\n",
    "for f in filtered_files:\n",
    "    # print(f)\n",
    "    dataset_iterator = tf_record_iterator(f[0])\n",
    "    data_in_f = [convert_to_str(d) for d in dataset_iterator]\n",
    "    datasets.extend(data_in_f)\n",
    "\n",
    "    # with open(f[1], 'w') as jf:\n",
    "    #     json.dump(data_in_f, jf)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "words = []\n",
    "for dataset in datasets:\n",
    "    words = words + dataset['text_sequence']\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "phonemes = np.array(words)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_phonemes = np.unique(phonemes)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "all_phonemes = all_phonemes.tolist()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "with open('/scratch/gilbreth/akamsali/Research/Makin/ecog2txt-pytorch/conf/vocab.words.1824', 'w') as f:\n",
    "    for phoneme in all_phonemes:\n",
    "        f.write(\"%s\\n\" % phoneme)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "files = {}\n",
    "for subject_id in subjects:\n",
    "    block_config = block_config_all[subject_id]\n",
    "\n",
    "    keys = list(block_config.keys())\n",
    "    files[subject_id] = list(map(lambda y: tfrecord_path + \"/EFC\" + subject_id + \"_B\" + y + \".tfrecord\", keys))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('research': conda)"
  },
  "interpreter": {
   "hash": "959b262981f9e08fc72aade93a85a5c75833c8c019f81d8706c5035adb92b56e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
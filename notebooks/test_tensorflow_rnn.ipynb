{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import ecog2txt.trainers as e2t_trainers\n",
    "import ecog2txt.data_generators"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Warning: package 'samplerate' not found; skipping\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "\n",
    "# CREATE A NEW MODEL\n",
    "trainer = e2t_trainers.MultiSubjectTrainer(\n",
    "    experiment_manifest_name=\"conf/mocha-1_word_sequence_orig.yaml\",\n",
    "    subject_ids=[400, 401],\n",
    "    SN_kwargs={\n",
    "        'FF_dropout': 0.4,          # overwriting whatever is in the manifest\n",
    "        'TEMPORALLY_CONVOLVE': True # overwriting whatever is in the manifest\n",
    "    },\n",
    "    DG_kwargs={\n",
    "        'REFERENCE_BIPOLAR': True,  # overwriting whatever is in the manifest\n",
    "    },\n",
    "    ES_kwargs = {\n",
    "        'data_mapping': {           # overwriting whatever is in the manifest\n",
    "            'encoder_inputs': 'ecog_sequence',\n",
    "            'decoder_targets': 'text_sequence',\n",
    "        },\n",
    "    },\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Setting feature_list for decoder_targets to training-intersection/validation-union\n",
      "\n",
      ".\n",
      "...\n",
      "........\n",
      ".\n",
      ".\n",
      "All tf_records have been written...\n",
      "Setting feature_list for decoder_targets to training-intersection/validation-union\n",
      "\n",
      ".\n",
      "...\n",
      "........\n",
      ".\n",
      ".\n",
      "All tf_records have been written...\n",
      "Creating a sequence network that will train on 100% of the training data\n",
      "Temporal convolution; enforcing ASSESS_ALL_DECIMATIONS = False...\n"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# MAKE SURE ALL THE TFRECORDS ARE WRITTEN\n",
    "for subject in trainer.ecog_subjects:\n",
    "    subject.write_tf_records_maybe()\n",
    "trainer.subject_to_table()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "...\n",
      ".\n",
      ".\n",
      "........\n",
      ".\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "    encoder_inputs decoder_targets text_sequence_vocab_list  \\\n",
       "400            448               3    [<pad>, <EOS>, <OOV>]   \n",
       "401            429               3    [<pad>, <EOS>, <OOV>]   \n",
       "\n",
       "                                           block_types  \\\n",
       "400  {'testing': {'mocha-1'}, 'training': {'mocha-1...   \n",
       "401  {'testing': {'mocha-1'}, 'training': {'mocha-1...   \n",
       "\n",
       "                                             block_ids decimation_factor  \\\n",
       "400  {'testing': {}, 'training': {72, 3, 23}, 'vali...                12   \n",
       "401  {'testing': {87}, 'training': {66, 4, 69, 41, ...                12   \n",
       "\n",
       "    restore_epoch  \n",
       "400          None  \n",
       "401          None  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encoder_inputs</th>\n",
       "      <th>decoder_targets</th>\n",
       "      <th>text_sequence_vocab_list</th>\n",
       "      <th>block_types</th>\n",
       "      <th>block_ids</th>\n",
       "      <th>decimation_factor</th>\n",
       "      <th>restore_epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>448</td>\n",
       "      <td>3</td>\n",
       "      <td>[&lt;pad&gt;, &lt;EOS&gt;, &lt;OOV&gt;]</td>\n",
       "      <td>{'testing': {'mocha-1'}, 'training': {'mocha-1...</td>\n",
       "      <td>{'testing': {}, 'training': {72, 3, 23}, 'vali...</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>429</td>\n",
       "      <td>3</td>\n",
       "      <td>[&lt;pad&gt;, &lt;EOS&gt;, &lt;OOV&gt;]</td>\n",
       "      <td>{'testing': {'mocha-1'}, 'training': {'mocha-1...</td>\n",
       "      <td>{'testing': {87}, 'training': {66, 4, 69, 41, ...</td>\n",
       "      <td>12</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "t = trainer.subject_to_table()\n",
    "t.block_ids[401]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'testing': {87},\n",
       " 'training': {4, 41, 57, 61, 66, 69, 73, 77},\n",
       " 'validation': {83}}"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# TRAIN THE TWO SUBJECTS IN PARALLEL\n",
    "assessments = trainer.parallel_transfer_learn()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "step 800: validation decoder accuracy (401) = 0.91\n",
      "\u001b[46mexample validation reference:\u001b[0m\n",
      "\u001b[41m\taddition and subtraction are learned skills\u001b[0m\n",
      "\u001b[46mexample validation hypothesis:\u001b[0m\n",
      "\u001b[42m1.00\taddition and subtraction are learned skills\u001b[0m\n",
      "\n",
      "\u001b[46maddition and subtraction are learned skills                  addition and subtraction are learned skills\u001b[0m\n",
      "\u001b[46mdon't do charlie dirty dishes                                don't do charlie dirty dishes\u001b[0m\n",
      "\u001b[46mcatastrophic economic cutbacks neglect the poor              catastrophic economic cutbacks neglect the poor\u001b[0m\n",
      "\u001b[46mmost young rabbits rise early every morning                  only lawyers most review every formula\u001b[0m\n",
      "\u001b[46mbasketball can be an entertaining sport                      basketball can be an entertaining sport\u001b[0m\n",
      "\u001b[46mget a calico cat to keep the rodents away                    basketball can be an entertaining sport\u001b[0m\n",
      "\u001b[46mthat pickpocket was caught red handed                        that pickpocket was caught red handed\u001b[0m\n",
      "\u001b[46mgrandmother outgrew her upbringing in petticoats             grandmother outgrew her upbringing in petticoats\u001b[0m\n",
      "\u001b[46malthough always alone we survive                             although always alone we survive\u001b[0m\n",
      "\u001b[46mthis was easy for us                                         is this seesaw safe\u001b[0m\n",
      "\u001b[46mtina turner is a pop singer                                  tina turner is a pop singer\u001b[0m\n",
      "\u001b[46mjane may earn more money by working hard                     jane may earn more money by working hard\u001b[0m\n",
      "\u001b[46mat twilight on the twelfth day we'll have chablis            at twilight on the twelfth day we'll have chablis\u001b[0m\n",
      "\u001b[46mshe is thinner than i am                                     she is thinner than i am\u001b[0m\n",
      "\u001b[46mthose thieves stole thirty jewels                            those thieves stole thirty jewels\u001b[0m\n",
      "\u001b[46ma good attitude is unbeatable                                a good attitude is unbeatable\u001b[0m\n",
      "\u001b[46mare your grades higher or lower than nancy                   are your grades higher or lower than nancy\u001b[0m\n",
      "\u001b[46mcritical equipment needs proper maintenance                  critical equipment needs proper maintenance\u001b[0m\n",
      "\u001b[46mcoconut cream pie makes a nice dessert                       coconut cream pie makes a nice dessert\u001b[0m\n",
      "\u001b[46mthe museum hires musicians every evening                     the museum hires musicians every evening\u001b[0m\n",
      "\u001b[46mswing your arm as high as you can                            swing your arm as high as you can\u001b[0m\n",
      "\u001b[46monly the most accomplished artists obtain popularity         only the most accomplished artists obtain\u001b[0m\n",
      "\u001b[46metiquette mandates compliance with existing regulations      etiquette mandates compliance with existing regulations\u001b[0m\n",
      "\u001b[46mnothing is as offensive as innocence                         nothing is as offensive as innocence\u001b[0m\n",
      "\u001b[46myoung people participate in athletic activities              young people participate in athletic activities\u001b[0m\n",
      "\u001b[46mis this seesaw safe                                          is this seesaw safe\u001b[0m\n",
      "\u001b[46monly lawyers love millionaires                               only lawyers love millionaires\u001b[0m\n",
      "\u001b[46maluminium cutlery can often be flimsy                        aluminium cutlery can often be flimsy\u001b[0m\n",
      "\u001b[46mdid dad do academic bidding                                  did dad do academic bidding\u001b[0m\n",
      "\u001b[46mbeg that guard for one gallon of petrol                      beg that guard for one gallon of petrol\u001b[0m\n",
      "\u001b[46mbiblical scholars argue history                              biblical scholars argue history\u001b[0m\n",
      "\u001b[46mbarb gold bracelet was a graduation present                  barb gold bracelet was a graduation present\u001b[0m\n",
      "\u001b[46melderly people are often excluded                            elderly people are often excluded\u001b[0m\n",
      "\u001b[46mbefore thursday exam review every formula                    before thursday exam review every formula\u001b[0m\n",
      "\u001b[46mmum strongly dislikes appetizers                             mum strongly dislikes appetizers\u001b[0m\n",
      "\u001b[46mthose musicians harmonize marvellously                       those musicians harmonize marvellously\u001b[0m\n",
      "\u001b[46mstimulating discussions keep students attention              stimulating discussions keep students attention\u001b[0m\n",
      "\u001b[46mwhy yell or worry over silly items                           why yell or worry over silly items\u001b[0m\n",
      "\u001b[46mcarl lives in a lively home                                  carl lives in a lively home\u001b[0m\n",
      "\u001b[46mwill robin wear a yellow lily                                will robin wear a yellow lily\u001b[0m\n",
      "\u001b[46mwhen all else fails use force                                when all else fails use force\u001b[0m\n",
      "\u001b[46mshe wore warm fleecy woolen overalls                         she wore warm fleecy woolen overalls\u001b[0m\n",
      "\u001b[46mbright sunshine shimmers on the ocean                        she is thinner than i am\u001b[0m\n",
      "\u001b[46malfalfa is healthy for you                                   alfalfa is healthy for you\u001b[0m\n",
      "\u001b[46ma roll of wire lay near the wall                             a roll of wire lay near the wall\u001b[0m\n",
      "\u001b[46malimony harms a divorced man wealth                          alimony harms a divorced man wealth\u001b[0m\n",
      "\u001b[46mhelp greg to pick a peck of potatoes                         help greg to pick a peck of potatoes\u001b[0m\n",
      "\u001b[46mwhere were you while we were away                            where were you while we were away\u001b[0m\n",
      "\u001b[46mhelp celebrate your brother success                          help celebrate your brother success\u001b[0m\n",
      "\u001b[46mhe will allow a rare lie                                     he will allow a rare lie\u001b[0m\n",
      "\n",
      "save file is /Users/akshita/Documents/Research/Makin/data/ecog2txt/word_sequence/saved_results/accuracies_EFC400-401_0.4_0.5_150__800_225_100_400-400-400\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/akshita/Documents/Research/Makin/data/ecog2txt/word_sequence/saved_results/accuracies_EFC400-401_0.4_0.5_150__800_225_100_400-400-400'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-387aa00a0059>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TRAIN THE TWO SUBJECTS IN PARALLEL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0massessments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_transfer_learn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Research/Makin/ecog2txt/ecog2txt/trainers.py\u001b[0m in \u001b[0;36mparallel_transfer_learn\u001b[0;34m(self, RESUME, fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m# fit and save the results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0massessments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mecog_subjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massessments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0;31m# to facilitate restoring/assessing, update hard-coded restore_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research/Makin/ecog2txt/ecog2txt/trainers.py\u001b[0m in \u001b[0;36m_save_results\u001b[0;34m(self, assessments)\u001b[0m\n\u001b[1;32m    547\u001b[0m                              np.array(accuracies_epochs)], axis=1),\n\u001b[1;32m    548\u001b[0m                    \u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"%.4f\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m                    header=('training accs | training WERs | '\n\u001b[0m\u001b[1;32m    550\u001b[0m                            'validation acc | validation WERs | epochs')\n\u001b[1;32m    551\u001b[0m                    )\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/Documents/Research/research_env/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36msavetxt\u001b[0;34m(fname, X, fmt, delimiter, newline, header, footer, comments, encoding)\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \u001b[0;31m# datasource doesn't support creating a new file ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1357\u001b[0;31m         \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1358\u001b[0m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m         \u001b[0mown_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/akshita/Documents/Research/Makin/data/ecog2txt/word_sequence/saved_results/accuracies_EFC400-401_0.4_0.5_150__800_225_100_400-400-400'"
     ]
    }
   ],
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('research': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "interpreter": {
   "hash": "959b262981f9e08fc72aade93a85a5c75833c8c019f81d8706c5035adb92b56e"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}